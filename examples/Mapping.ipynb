{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SLAM algorithm step by step\n",
    "This notebooks allows to perform step-by-step matching of the scans registered in a small apartment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from src.grid_maps import log_odds, prob\n",
    "from src.scan_processing import scan2xy\n",
    "import src.feature_detection as features\n",
    "import src.hc as hc\n",
    "import src.icp as icp\n",
    "import src.graphslam as gs\n",
    "\n",
    "import src.grid_maps as g\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the notebook it is needed to preprocess the scans and saved odomtery data using `prepare_scans.py` script.\n",
    "The script:\n",
    "- groups scans taken in same places\n",
    "- removes scans taken while moving\n",
    "- estimates robot poses based on saved odometry or controls\n",
    "\n",
    "```\n",
    "python ..\\src\\prepare_scans.py\n",
    "```\n",
    "\n",
    "The results are stored in `mapping.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapping.pickle', 'rb') as f:\n",
    "    (scans, poses, controls) = pickle.load(f)\n",
    "\n",
    "# combine poses into a single array\n",
    "poses = np.vstack(poses)\n",
    "\n",
    "# remove the first scan (usually taken in a static position before the procedure's start)\n",
    "scans = scans[1:]\n",
    "poses_odo = poses[1:]\n",
    "controls = controls[1:]\n",
    "\n",
    "# change controls\n",
    "controls = np.vstack(controls)\n",
    "controls[:,0] = controls[:,0]*0.7 # to account for lower robot speed\n",
    "controls[:,1] = controls[:,1] *1\n",
    "\n",
    "# estimate robot poses based on the controls\n",
    "poses_odo = []\n",
    "posodo = np.r_[0,0,0]\n",
    "\n",
    "for c in controls:\n",
    "    posodo = posodo + np.r_[np.cos(posodo[2])*c[0], np.sin(posodo[2])*c[0], c[1]]\n",
    "    poses_odo.append(posodo)\n",
    "    \n",
    "poses_odo = np.vstack(poses_odo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLAM Parameters\n",
    "The SLAM algorithm takes parameters governing its steps - line extraction from the scans, association thresholds for ICP points etc. The detailed explanation can be found in the paper:\n",
    "\n",
    "**M. Kolakowski, “Automated Calibration of RSS Fingerprinting Based Systems Using a Mobile Robot and Machine Learning”, Sensors , vol. 21, 6270, Sep. 2021 https://doi.org/10.3390/s21186270**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = {\n",
    "    \"extr_angle_range\": np.pi / 3,\n",
    "    \"extr_split_th\": 0.1,\n",
    "    \"extr_min_len\": 0.6,\n",
    "    \"extr_min_points\": 10,\n",
    "\n",
    "    \"mrg_max_dist\": -0.2,\n",
    "    \"mrg_a_tol\": 0.1,\n",
    "    \"mrg_b_tol\": 0.1,\n",
    "    \"mrg_fit_tol\": 0.1,\n",
    "\n",
    "    \"association_th\": [0.3],\n",
    "\n",
    "    \"an_th\": 0.3,\n",
    "    \"d_th\": 0.2,\n",
    "    \"corr_points_th\": 0.1\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICP matching of consecutive scans\n",
    "The scans are consecutively matched to each other to obtain a rough map of the entire apartment for the first GraphSLAM iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = []\n",
    "fig, axs = plt.subplots(int(len(scans)/8+1), 8, figsize=(24, 3*int(len(scans)/8+1)))\n",
    "\n",
    "heading = 0\n",
    "\n",
    "progress_bar = tqdm(range(len(scans)))\n",
    "\n",
    "for i, ax in zip(range(len(scans)-1), axs.ravel()[:]):\n",
    "#     clear_output(wait=True)\n",
    "#     print(i)\n",
    "    s1 = scans[i]\n",
    "    s2 = scans[i+1]\n",
    "    c = controls[i+1]\n",
    "    ic = np.r_[np.cos(heading)*c[0], np.sin(heading)*c[0], c[1]]\n",
    "    H = icp.transformation_matrix(ic[2], ic[:2])\n",
    "    ic = np.r_[H[:2, 2], c[1]]\n",
    "#     print(ic)\n",
    "    try:\n",
    "        t = icp.match_scans(s1,s2, ic, sp, iters=5)\n",
    "    except:\n",
    "        print(\"Error for scan {}\".format(i))\n",
    "        t = np.r_[1,1,1]*np.nan\n",
    "        \n",
    "    transformations.append(t)\n",
    "    Hi = icp.transformation_matrix(ic[2], ic[:2])\n",
    "    \n",
    "    \n",
    "    H = hc.translation(t[:2]).dot(hc.rotation(t[2]))\n",
    "\n",
    "    s1h = hc.ec_hc(s1[:,:2])\n",
    "    s2h = hc.ec_hc(s2[:,:2])\n",
    "\n",
    "    s2t = H.dot(s2h)\n",
    "    s2i = Hi.dot(s2h)\n",
    "\n",
    "    ax.set_title(i)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.scatter(s1.T[0], s1.T[1], s=3)\n",
    "    ax.scatter(s2i[0], s2i[1], marker='.', s=1)\n",
    "    ax.scatter(s2t[0], s2t[1], marker='.', s=1)\n",
    "    ax.grid()\n",
    "    progress_bar.update(1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('icp_trans_mapping.pickle', 'wb') as f:\n",
    "    pickle.dump(transformations, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all of the ICP transformations were computed. If any row is `False` repeat the fitting procedure for the given scan pair using different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.isnan(transformations).all(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = {\n",
    "    \"extr_angle_range\": np.pi / 3,\n",
    "    \"extr_split_th\": 0.1,\n",
    "    \"extr_min_len\": 0.3,\n",
    "    \"extr_min_points\": 10,\n",
    "\n",
    "    \"mrg_max_dist\": -0.2,\n",
    "    \"mrg_a_tol\": 0.1,\n",
    "    \"mrg_b_tol\": 0.1,\n",
    "    \"mrg_fit_tol\": 0.1,\n",
    "\n",
    "    \"association_th\": [0.3],\n",
    "\n",
    "    \"an_th\": 0.9,\n",
    "    \"d_th\": 0.9,\n",
    "    \"corr_points_th\": 0.4\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading=0\n",
    "for i in [77]:\n",
    "\n",
    "    s1 = scans[i]\n",
    "    s2 = scans[i+1]\n",
    "    c = controls[i+1]\n",
    "    ic = np.r_[np.cos(heading)*c[0], np.sin(heading)*c[0], c[1]]\n",
    "    H = icp.transformation_matrix(ic[2], ic[:2])\n",
    "    ic = np.r_[H[:2, 2], c[1]]\n",
    "\n",
    "    try:\n",
    "        t = icp.match_scans(s1,s2, ic, sp, iters=7)\n",
    "    except:\n",
    "        print(\"Error for scan {}\".format(i))\n",
    "        t = np.r_[1,1,1]*np.nan\n",
    "        \n",
    "    transformations[i] = t\n",
    "    Hi = icp.transformation_matrix(ic[2], ic[:2])\n",
    "    \n",
    "    \n",
    "    H = hc.translation(t[:2]).dot(hc.rotation(t[2]))\n",
    "\n",
    "    s1h = hc.ec_hc(s1[:,:2])\n",
    "    s2h = hc.ec_hc(s2[:,:2])\n",
    "\n",
    "    s2t = H.dot(s2h)\n",
    "    s2i = Hi.dot(s2h)\n",
    "    \n",
    "    plt.title(i)\n",
    "    plt.axes().set_aspect('equal')\n",
    "    plt.scatter(s1.T[0], s1.T[1], s=3)\n",
    "    plt.scatter(s2i[0], s2i[1], marker='.', s=1)\n",
    "    plt.scatter(s2t[0], s2t[1], marker='.', s=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the complete transformations list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('icp_trans_mapping2.pickle', 'wb') as f:\n",
    "    pickle.dump(transformations, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize initial estimate of poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = pickle.load(open('icp_trans_mapping2.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "heading = 0\n",
    "pose = np.r_[0,0,0]\n",
    "poses.append(pose)\n",
    "for t in transformations[:]:\n",
    "\n",
    "    heading = poses[-1][2] + t[2]\n",
    "    px = poses[-1][0] +  t[0]* np.cos(heading)- t[1]* np.sin(heading)\n",
    "    py = poses[-1][1] +  t[1]* np.cos(heading)+ t[0]* np.sin(heading)\n",
    "    ph = poses[-1][2] + t[2]\n",
    "    pose = np.r_[px, py, ph]\n",
    "    \n",
    "    poses.append(pose)\n",
    "poses = np.vstack(poses)\n",
    "\n",
    "plt.figure()\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.plot(poses.T[0],poses.T[1], marker='o' ,label='icp matching')\n",
    "plt.plot(poses_odo.T[0], poses_odo.T[1], marker='o', label='odometry')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSLAM \n",
    "\n",
    "### Graph initialization\n",
    "The graph is initialized with poses resulting from the odometry measurements. The edges are the results of the consecutive scans ICP fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = {\n",
    "    \"extr_angle_range\": np.pi / 3,\n",
    "    \"extr_split_th\": 0.2,\n",
    "    \"extr_min_len\": 0.6,\n",
    "    \"extr_min_points\": 10,\n",
    "\n",
    "    \"mrg_max_dist\": -0.2,\n",
    "    \"mrg_a_tol\": 0.1,\n",
    "    \"mrg_b_tol\": 0.1,\n",
    "    \"mrg_fit_tol\": 0.1,\n",
    "\n",
    "    \"association_th\": [0.4],\n",
    "\n",
    "    \"an_th\": 0.3,\n",
    "    \"d_th\": 0.2,\n",
    "    \"corr_points_th\": 0.06\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize graph\n",
    "graph = gs.Graph()\n",
    "graph.init_nodes(poses_odo)\n",
    "graph.init_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, i in zip(transformations, range(len(transformations))):\n",
    "    graph.add_icp_edge(i, i+1, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gs.run_graphSlam(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_graph(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(graph, open('graph1.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to find constraints between the non consecutive scans. A single iteration is implemented using `graphSLAM_iter` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphSLAM_iter(graph, max_distance, min_common_map, scans):\n",
    "    icp_candidates = gs.find_icp_candidates(graph, max_distance, min_common_map, scans)\n",
    "    print('Starting graphSLAM for max_distance: {} and min_common_map: {}'.format(max_distance, min_common_map))\n",
    "    i = 1\n",
    "    while len(icp_candidates)>0:\n",
    "        print('Iteration {}, found {} scan pairs for ICP'.format(i, len(icp_candidates)))\n",
    "       \n",
    "        # get transformations\n",
    "        print('getting ICP edges...')\n",
    "        progress_bar = tqdm(range(len(icp_candidates)))\n",
    "\n",
    "        gs.create_icp_edges(graph, scans, icp_candidates, sp,progress_bar)\n",
    "\n",
    "        # run graphslam\n",
    "        print('optimizing graph...' )\n",
    "        x = gs.run_graphSlam(graph)\n",
    "        graph.update_graph(x)\n",
    "        graph.plot()\n",
    "\n",
    "        # dump\n",
    "        pickle.dump(graph, open('graph.pickle', 'wb'))\n",
    "\n",
    "        # check if there are other candidates\n",
    "        icp_candidates = gs.find_icp_candidates(graph, max_distance, min_common_map, scans)\n",
    "\n",
    "    print('No more new edges for the parameters. Change max_distance and min_common_map and run again.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gridmap(graph):\n",
    "    \n",
    "    xrs = graph.get_poses()\n",
    "\n",
    "    size= 20\n",
    "    res= 0.04\n",
    "    gridmap = g.init_gridmap(size, res)\n",
    "\n",
    "    for s, p in zip(scans[:49], xrs[:49]):\n",
    "        H = hc.translation(p[:2]).dot(hc.rotation(p[2]))\n",
    "        st = H.dot(hc.ec_hc(s[:,:2]))\n",
    "    #     r = np.linalg.norm(st[:,:2]-p[:2], axis=1)\n",
    "        gmap = g.points2gridmap(size, res, p, st)\n",
    "\n",
    "        gridmap = g.merge_maps(gridmap, gmap)\n",
    "\n",
    "\n",
    "    for s, p in zip(scans[51:], xrs[51:]):\n",
    "        H = hc.translation(p[:2]).dot(hc.rotation(p[2]))\n",
    "        st = H.dot(hc.ec_hc(s[:,:2]))\n",
    "    #     r = np.linalg.norm(st[:,:2]-p[:2], axis=1)\n",
    "        gmap = g.points2gridmap(size, res, p, st)\n",
    "\n",
    "        gridmap = g.merge_maps(gridmap, gmap)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(gridmap, cmap='bone_r')\n",
    "    \n",
    "    return gridmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphSLAM_iter(graph, 1, 0.8, scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gridmap(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphSLAM_iter(graph, 1, 0.75, scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphSLAM_iter(graph, 1, 0.7, scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gridmap(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphSLAM_iter(graph, 1.5, 0.75, scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gridmap(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphSLAM_iter(graph, 1.5, 0.7, scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphSLAM_iter(graph, 2, 0.6, scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gridmap(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final gridmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_scans(scans, scan_points):\n",
    "    \"\"\"Center the scans so that the resulting gridmap will be as small as possible\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scans: list\n",
    "        scans [x,y] format\n",
    "    scan_points: ndarray\n",
    "        scan locations\n",
    "    trans: ndarray\n",
    "        values which was subtracted from the points \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    centered: list\n",
    "        centered scans\n",
    "    scans_locs: ndarray\n",
    "        updated scan locations\n",
    "    med: ndarray\n",
    "        transformation, which was applied (the value should be subtracted from the x-y coordinates if there's a need to\n",
    "        transform other points\n",
    "    \"\"\"\n",
    "    min = np.min(scan_points, axis=0)\n",
    "    max = np.max(scan_points, axis=0)\n",
    "    med = (min + max) / 2\n",
    "    centered = []\n",
    "    for s in scans:\n",
    "        centered.append(s - med)\n",
    "\n",
    "    scan_locs = scan_points - med\n",
    "    return centered, scan_locs, med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform scan points according to the computed poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrs = graph.get_poses()\n",
    "gridmap = g.init_gridmap(size, res)\n",
    "scans_trans = []\n",
    "for s, p in zip(scans, xrs):\n",
    "    H = hc.translation(p[:2]).dot(hc.rotation(p[2]))\n",
    "    st = hc.hc_ec(H.dot(hc.ec_hc(s[:,:2])))\n",
    "    scans_trans.append(st)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center scans and compute shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered, scan_locs, med = center_scans(scans_trans,np.vstack(xrs)[:,:2])\n",
    "\n",
    "all_points = np.vstack(centered)\n",
    "size = tuple(e for e in np.abs(all_points).max(axis=0) * 2+ 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set gridmap parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridmap resolution\n",
    "gridmap_res = 0.05\n",
    "\n",
    "# gridmap size override, which might be needed in case of some outlier points\n",
    "size = (11,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create gridmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridmaps=[]\n",
    "for s, p, angle in zip(centered, scan_locs, np.vstack(xrs)[:,2]):\n",
    "    gmap = g.points2gridmap(size, gridmap_res, np.r_[p, angle], hc.ec_hc(s) )\n",
    "    gridmaps.append(gmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge into one map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap = gridmaps[0]\n",
    "\n",
    "for gr in gridmaps[1:]:\n",
    "    gmap = g.merge_maps(gmap, gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(gmap, cmap='bone_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an image using PIL and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to an image\n",
    "img = Image.fromarray(np.uint8((1-gmap) * 255) , 'L')\n",
    "img = img.convert('RGB')\n",
    "\n",
    "# save image\n",
    "img.save('map.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
